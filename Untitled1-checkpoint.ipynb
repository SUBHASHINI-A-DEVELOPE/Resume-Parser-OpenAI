{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d701a2a-dd85-472e-92de-f5da6b6e5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "796b505b-7d7e-404c-b263-5a2c6e6a21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from pdfminer3.layout import LAParams, LTTextBox\n",
    "from pdfminer3.pdfpage import PDFPage\n",
    "from pdfminer3.pdfinterp import PDFResourceManager\n",
    "from pdfminer3.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer3.converter import TextConverter\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d13e546b-0640-4967-81c9-6853f932cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyA9oNzA2KZdFJrQRlr3nV_cc-_QakneJEI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0caa3ab6-85d2-47f7-a0b2-761f4a26c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8b73743-a750-4e7e-83a3-5cb665b09d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_reader(file):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle, laparams=LAParams())\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "    with open(file, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh,\n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    "            print(page)\n",
    "        text = fake_file_handle.getvalue()\n",
    "\n",
    "    # close open handles\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed3fcd00-4e23-48ef-9375-be66c05692d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(llm,resume_text):\n",
    "        # Define the prompt template for parsing resumes\n",
    "    # resume_parsing_prompt = PromptTemplate(\n",
    "    #     input_variables=[\"resume_text\"],\n",
    "    #     template=\"Parse the following resume and extract person details,relevant skills, experiences, and qualifications:\\n\\n{resume_text}\\n\\nOutput as JSON.\"\n",
    "    # )\n",
    "\n",
    "    resume_parsing_prompt = PromptTemplate(\n",
    "    input_variables=[\"resume_text\"],\n",
    "    template=(\n",
    "        \"Parse the following resume and extract the person details, relevant skills, experiences, and qualifications. \"\n",
    "        \"Ensure the output is a JSON object with the following keys: \"\n",
    "        \"'personDetails', 'skills', 'experiences', 'certifications','qualifications','achievements','projects','hobbies'. \"\n",
    "        \"If a field is not available, return it as an empty string or an empty list.\\n\\n\"\n",
    "        \"{resume_text}\\n\\n\"\n",
    "        \"Output as JSON with the specified keys.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "    parsing_chain = LLMChain(llm=llm, prompt=resume_parsing_prompt)\n",
    "    parsed_data = parsing_chain.run({\"resume_text\": resume_text})\n",
    "    parsed_data = json.loads(\"\".join(parsed_data.split(\"\\n\")[1:-1]))\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20590247-4e52-498e-9a3b-4498c927105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PDFPage: Resources={'ColorSpace': <PDFObjRef:17>, 'ExtGState': <PDFObjRef:15>, 'Font': {'F23': <PDFObjRef:20>, 'F24': <PDFObjRef:21>, 'F28': <PDFObjRef:22>, 'F33': <PDFObjRef:19>, 'F44': <PDFObjRef:25>, 'F45': <PDFObjRef:23>, 'F47': <PDFObjRef:24>, 'F57': <PDFObjRef:26>}, 'Pattern': <PDFObjRef:16>, 'ProcSet': [/'PDF', /'Text']}, MediaBox=[0, 0, 595.276, 841.89]>\n"
     ]
    }
   ],
   "source": [
    "text = pdf_reader(\"uploads/Abhishak_Resume.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39687a01-5813-48fb-8923-03035e987c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personDetails': {'name': 'Abhishek Varshney',\n",
       "  'email': 'abhishakvarshney@gmail.com',\n",
       "  'phone': '+91-8433489919',\n",
       "  'github': 'github.com/abhishakvarshney',\n",
       "  'linkedin': 'linkedin.com/in/abhishakvarshney',\n",
       "  'live': 'live:abhishakvarshney'},\n",
       " 'skills': ['Python',\n",
       "  'R-Language',\n",
       "  'MS-Excel',\n",
       "  'Google Analytics',\n",
       "  'MySQL',\n",
       "  'MongoDB',\n",
       "  'Git',\n",
       "  'Nginx',\n",
       "  'Supervisord'],\n",
       " 'experiences': [{'title': 'Software Engineer-Analytics',\n",
       "   'company': 'Skilrock Technologies | Sugal & Damani Group',\n",
       "   'location': 'Gurugram, India',\n",
       "   'startDate': 'June 2018',\n",
       "   'endDate': 'Present',\n",
       "   'description': 'Developed an NLP-based chatbot in Python that allows users to play games, purchase tickets, and chat with the chatbot.\\nDeployed the chatbot on Skilrock Technologies Client Gaming and Lottery Engine website, Android and iOS Apps, and on Facebook Messenger.\\nTechnologies used: Python | Rasa, Microsoft Bot Framework'},\n",
       "  {'title': 'Trainee | Internship',\n",
       "   'company': 'Tata Steel',\n",
       "   'location': 'Jamshedpur, India',\n",
       "   'startDate': 'May 2017',\n",
       "   'endDate': 'July 2017',\n",
       "   'description': 'Analyzed and Balanced Heat and Mass data from Raw Material to liquid steel making process i.e. from raw to production.\\nTechnology: MS–Excel'}],\n",
       " 'certifications': ['Machine Learning: Coursera',\n",
       "  'R Basics – R Programming Language Introduction: Udemy',\n",
       "  'Introduction to Python Programming: Udemy',\n",
       "  'MongoDB Basics: MongoDBInc. – MongoDB University',\n",
       "  'SQL Fundamental Course: SOLOLearn'],\n",
       " 'qualifications': [{'degree': 'B.Tech-Metallurgical & Materials Engineering',\n",
       "   'university': 'NIT Jaipur (MNIT/MREC)',\n",
       "   'startDate': '2014',\n",
       "   'endDate': '2018',\n",
       "   'cgpa': '7.5'},\n",
       "  {'degree': 'Intermediate (+2)',\n",
       "   'university': 'B.B.S.S.M. Inter College',\n",
       "   'startDate': '2012',\n",
       "   'endDate': '2013',\n",
       "   'percentage': '91.00%'},\n",
       "  {'degree': 'High-School',\n",
       "   'university': 'B.B.S.S.M. Inter College',\n",
       "   'startDate': '2010',\n",
       "   'endDate': '2011',\n",
       "   'percentage': '72.83%'}],\n",
       " 'achievements': ['Placed in top 21% in Housing Price Prediction Kaggle challenge',\n",
       "  'Secured II rank in ‘International Robotics Challenge – Sixth Sense Robotics – 2014’ organized by ‘ROBOTech Labs and IIT-Bombay’',\n",
       "  'Participated in ‘58th National School Skating Championship 2012-13’ organized by ‘Indian Olympic Association’',\n",
       "  'Secured I rank in ‘State Skating Championship-2012’ organized by ‘Vidya-Bharti’ at Meerut'],\n",
       " 'projects': [{'title': 'Stanford Open Policing Project-California',\n",
       "   'description': 'Prediction of traffic stop rates, their times’ and places that reliably generate stops.\\nTechnology: Time-Series Analysis | ARIMA Model | R Language'},\n",
       "  {'title': 'Housing Price Prediction',\n",
       "   'description': 'Prediction of Sale Price of Houses in USA based on various features.\\nTechnology: Random Forest | R Language'},\n",
       "  {'title': 'Twitter Text Mining',\n",
       "   'description': 'Extract data from twitter and Predicts the sentiments of four pharma companies: Bayer, Pfizer, Roche and Novartis.\\nTechnology: Naive Bayes Theorem | R Language'},\n",
       "  {'title': 'Image Processing: Object Detection',\n",
       "   'description': 'A Python-based application which can detect different objects. Detected raccoon, horses, dogs and cats in various images and videos using trained data/images.\\nTechnology: CNN, YOLO | Python-Tensorflow, Keras, OpenCV'},\n",
       "  {'title': 'Linux Path Traversal',\n",
       "   'description': 'Created virtual linux terminal that can execute various commands: md, cd, cd.., ls, pwd, dir, rm, cp, mv, session_clean.\\nTechnology: Python'}],\n",
       " 'hobbies': ['Skating', 'Travelling']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_data(llm,resume_text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2def4a1-ea75-47ce-ac10-87436c72ed90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Text\nid\n  Field required [type=missing, input_value={'name': 'Name', 'descrip... the resume belongs to'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m personal_details \u001b[38;5;241m=\u001b[39m Object(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume_extraction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextraction of relevant information from resume\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     attributes\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m----> 5\u001b[0m         \u001b[43mText\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mName of the resume belongs to\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     ],\n\u001b[1;32m      9\u001b[0m     many\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )        \n",
      "File \u001b[0;32m~/Projects/Resume-Parser/langchain_env/lib/python3.12/site-packages/kor/nodes.py:122\u001b[0m, in \u001b[0;36mExtractionSchemaNode.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m PYDANTIC_MAJOR_VERSION \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[TYPE_DISCRIMINATOR_FIELD] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/Projects/Resume-Parser/langchain_env/lib/python3.12/site-packages/pydantic/main.py:209\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    208\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    211\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    215\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    216\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Text\nid\n  Field required [type=missing, input_value={'name': 'Name', 'descrip... the resume belongs to'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/missing"
     ]
    }
   ],
   "source": [
    "personal_details = Object(\n",
    "    id=\"resume_extraction\",\n",
    "    description=\"extraction of relevant information from resume\",\n",
    "    attributes=[\n",
    "        Text(\n",
    "            name=\"Name\",\n",
    "            description= \"Name of the resume belongs to\",\n",
    "        # examples=[\n",
    "        #     (\"Invoice Number: INV-23490\", \"INV-23490\"),\n",
    "        #     (\"INVNO-76890\", \"INVNO-76890\"),\n",
    "        #     (\"Invoice: INV-100021\", \"INV-100021\")\n",
    "        # ]\n",
    "        )\n",
    "    ],\n",
    "    many=False,\n",
    ")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b1802-fed0-4d89-9b7c-59491b7d094d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
